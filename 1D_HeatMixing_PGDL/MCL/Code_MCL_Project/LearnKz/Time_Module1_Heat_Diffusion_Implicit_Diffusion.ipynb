{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.283408</td>\n",
       "      <td>16.149422</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.206994</td>\n",
       "      <td>16.241692</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.283408</td>\n",
       "      <td>16.267964</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.206994</td>\n",
       "      <td>16.247184</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.287068</td>\n",
       "      <td>16.286071</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.286071</td>\n",
       "      <td>16.251763</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.291257</td>\n",
       "      <td>16.288695</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.288695</td>\n",
       "      <td>16.251763</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>695.937161</td>\n",
       "      <td>-56.268384</td>\n",
       "      <td>-23.291619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>16.278268</td>\n",
       "      <td>16.270156</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>16.270156</td>\n",
       "      <td>16.256606</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141570</th>\n",
       "      <td>21</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.537687</td>\n",
       "      <td>8.537921</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>8.537921</td>\n",
       "      <td>8.537921</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141571</th>\n",
       "      <td>22</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>7.466041</td>\n",
       "      <td>7.466186</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>7.466186</td>\n",
       "      <td>7.466186</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141572</th>\n",
       "      <td>23</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.396040</td>\n",
       "      <td>6.396125</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.396125</td>\n",
       "      <td>6.396125</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141573</th>\n",
       "      <td>24</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>5.326140</td>\n",
       "      <td>5.326179</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.326179</td>\n",
       "      <td>5.326179</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141574</th>\n",
       "      <td>25</td>\n",
       "      <td>21.695001</td>\n",
       "      <td>832.055902</td>\n",
       "      <td>-93.493728</td>\n",
       "      <td>-12.091248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162606</td>\n",
       "      <td>1.049822</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>4.256585</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141575 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0           1     10.715021     695.937161   -56.268384     -23.291619   \n",
       "1           2     10.715021     695.937161   -56.268384     -23.291619   \n",
       "2           3     10.715021     695.937161   -56.268384     -23.291619   \n",
       "3           4     10.715021     695.937161   -56.268384     -23.291619   \n",
       "4           5     10.715021     695.937161   -56.268384     -23.291619   \n",
       "...       ...           ...            ...          ...            ...   \n",
       "141570     21     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141571     22     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141572     23     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141573     24     21.695001     832.055902   -93.493728     -12.091248   \n",
       "141574     25     21.695001     832.055902   -93.493728     -12.091248   \n",
       "\n",
       "        Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  \\\n",
       "0                  0.0          0.255324            1.085448   \n",
       "1                  0.0          0.255324            1.085448   \n",
       "2                  0.0          0.255324            1.085448   \n",
       "3                  0.0          0.255324            1.085448   \n",
       "4                  0.0          0.255324            1.085448   \n",
       "...                ...               ...                 ...   \n",
       "141570             0.0          1.162606            1.049822   \n",
       "141571             0.0          1.162606            1.049822   \n",
       "141572             0.0          1.162606            1.049822   \n",
       "141573             0.0          1.162606            1.049822   \n",
       "141574             0.0          1.162606            1.049822   \n",
       "\n",
       "        ShearStress_Nm-2     Area_m2  ...  buoyancy  diffusivity  temp_heat00  \\\n",
       "0               0.002290  36000000.0  ... -0.000006     0.000037    16.283408   \n",
       "1               0.002290  36000000.0  ... -0.000006     0.000037    16.283408   \n",
       "2               0.002290  36000000.0  ... -0.000007     0.000037    16.287068   \n",
       "3               0.002290  36000000.0  ...  0.000021     0.000037    16.291257   \n",
       "4               0.002290  36000000.0  ...  0.000180     0.000025    16.278268   \n",
       "...                  ...         ...  ...       ...          ...          ...   \n",
       "141570          0.002174  36000000.0  ...  0.000637     0.000014     8.537687   \n",
       "141571          0.002174  36000000.0  ...  0.000474     0.000016     7.466041   \n",
       "141572          0.002174  36000000.0  ...  0.000307     0.000020     6.396040   \n",
       "141573          0.002174  36000000.0  ...  0.000134     0.000028     5.326140   \n",
       "141574          0.002174  36000000.0  ...  0.000134     0.000028     4.256585   \n",
       "\n",
       "        temp_diff01  day_of_year  time_of_day  temp_mix02  temp_conv03  \\\n",
       "0         16.149422          155            1   16.206994    16.241692   \n",
       "1         16.267964          155            1   16.206994    16.247184   \n",
       "2         16.286071          155            1   16.286071    16.251763   \n",
       "3         16.288695          155            1   16.288695    16.251763   \n",
       "4         16.270156          155            1   16.270156    16.256606   \n",
       "...             ...          ...          ...         ...          ...   \n",
       "141570     8.537921          213           23    8.537921     8.537921   \n",
       "141571     7.466186          213           23    7.466186     7.466186   \n",
       "141572     6.396125          213           23    6.396125     6.396125   \n",
       "141573     5.326179          213           23    5.326179     5.326179   \n",
       "141574     4.256585          213           23    4.256585     4.256585   \n",
       "\n",
       "        obs_temp  input_obs  \n",
       "0         16.409     16.350  \n",
       "1         16.480     16.426  \n",
       "2         16.130     16.088  \n",
       "3         15.827     15.789  \n",
       "4         16.270     16.240  \n",
       "...          ...        ...  \n",
       "141570     0.401      0.401  \n",
       "141571     0.401      0.401  \n",
       "141572     0.401      0.401  \n",
       "141573     0.401      0.401  \n",
       "141574     0.401      0.401  \n",
       "\n",
       "[141575 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 5663\n",
      "Number of training points: 84925\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'diffusivity' ,'temp_heat00']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (84925, 15), X_test: (56650, 15)\n",
      "y_train: (84925, 1), y_test: (56650, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1000\n",
    "\n",
    "assert batch_size % 25 ==0, \"Batchsize has to be multiple of 25\" \n",
    "\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "# mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "# std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "# mean_out = torch.tensor(output_mean).to(device)\n",
    "# std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "# def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "#     # de-normalise data\n",
    "#     diff = diff * std_diff + mean_diff\n",
    "\n",
    "#     # INPUT DATA FROM PREVIOUS MODULE\n",
    "#     t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "\n",
    "#     # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     j = len(t)\n",
    "#     y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "#     alpha = (dt/dx**2) * diff\n",
    "\n",
    "#     az = - alpha # subdiagonal\n",
    "#     bz = 2 * (1 + alpha) # diagonal\n",
    "#     cz = - alpha # superdiagonal\n",
    "\n",
    "#     bz[0] = 1\n",
    "#     az[len(az)-2] = 0\n",
    "#     bz[len(bz)-1] = 1\n",
    "#     cz[0] = 0\n",
    "\n",
    "#     az = az[1:,:]\n",
    "#     cz = cz[:-1,:]\n",
    "\n",
    "#     y = torch.diag(bz[:, 0])+torch.diag(az[:, 0],-1)+torch.diag(cz[:, 0],1) #slightly efficient way of computing the diagonal matrices\n",
    "#     y[j-1, j-1] = 1\n",
    "    \n",
    "#     mn = torch.zeros_like(t)  \n",
    "#     mn[0] = t[0]\n",
    "#     mn[len(mn)-1] = t[len(t)-1]\n",
    "    \n",
    "#     mn[1:j-1] = alpha[1:j-1,0]*t[:j-2] + 2 * (1 - alpha[1:j-1,0])*t[1:j-1] + alpha[1:j-1,0]*t[1:j-1] #is be same as the loop\n",
    "    \n",
    "#     # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "#     proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "#     mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "#     proj = (proj-mean_out)/std_out\n",
    "\n",
    "#     proj = proj.to(torch.double)\n",
    "#     return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 13, 14]\n",
      "13\n",
      "5\n",
      "[0, 1]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_column_ix[13])\n",
    "print(input_column_ix[5])\n",
    "print(input_column_ix[:2])\n",
    "print(input_column_ix[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "\n",
    "mean_temp = torch.tensor(input_mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(input_std[input_column_ix[14]]).to(device)\n",
    "\n",
    "mean_out = torch.tensor(output_mean).to(device)\n",
    "std_out = torch.tensor(output_std).to(device)\n",
    "    \n",
    "def implicit_diffusion(diff, temp, dt=3600, dx=1, depth_steps=25):\n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    diff = diff.view(-1, depth_steps)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    t = t.view(-1, depth_steps)\n",
    "    \n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "#     len_t = t.shape[1]\n",
    "    y = torch.zeros((t.shape[0], depth_steps, depth_steps), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * diff\n",
    "\n",
    "    az = - alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = - alpha # superdiagonal\n",
    "    \n",
    "    bz[:, 0] = 1\n",
    "    az[:, depth_steps-2] = 0\n",
    "    bz[:, depth_steps-1] = 1\n",
    "    cz[:, 0] = 0\n",
    "    \n",
    "    az = az[:,1:]\n",
    "    cz = cz[:,:-1]\n",
    "\n",
    "    y = torch.diag_embed(bz, offset=0)+torch.diag_embed(az,offset=-1)+torch.diag_embed(cz,offset=1) #slightly efficient way of computing the diagonal matrices\n",
    "    y[:, depth_steps-1, depth_steps-1] = 1\n",
    "    \n",
    "    mn = torch.zeros_like(t)  \n",
    "    mn[:, 0] = t[:, 0]\n",
    "    mn[:,depth_steps-1] = t[:, depth_steps-1]\n",
    "    \n",
    "    mn[:, 1:depth_steps-1] = alpha[:, 1:depth_steps-1]*t[:, :depth_steps-2] + 2 * (1 - alpha[:,1:depth_steps-1])*t[:,1:depth_steps-1] + alpha[:,1:depth_steps-1]*t[:,1:depth_steps-1] #is be same as the loop\n",
    "    \n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    proj = torch.linalg.solve(y, mn)\n",
    "\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.float32)\n",
    "    proj = proj.view(-1, 1)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "# temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)\n",
    "# mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "# std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "# print(mean_diff, std_diff)\n",
    "\n",
    "# pred = implicit_diffusion(diff=diffusivity_true, \n",
    "#                           temp=temp_heat_true)\n",
    "\n",
    "# print(torch.mean((pred-y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 20\n",
    "# # print(pred[25*time:25*(time+1)])\n",
    "# # print(y_train[25*time:25*(time+1)])\n",
    "# print((pred[25*time:25*(time+1)]-y_train[25*time:25*(time+1)]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:01<30:21,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train_loss: 0.007135356746285277, Test_loss: 3.830253387461294e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [03:00<1:27:26,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train_loss: 1.4729562206091085e-05, Test_loss: 2.8482539052850354e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [06:38<1:09:25,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, Train_loss: 1.2526385200865608e-05, Test_loss: 2.8199221113729372e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [10:02<1:04:34,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 150, Train_loss: 1.1317995594093671e-05, Test_loss: 2.8224291574524453e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [13:24<56:35,  4.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 200, Train_loss: 1.0576021138737868e-05, Test_loss: 2.8224417212441677e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [16:59<58:07,  4.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 250, Train_loss: 1.0753472633950877e-05, Test_loss: 2.8215879227214475e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [20:34<57:24,  4.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 300, Train_loss: 1.0840617120693957e-05, Test_loss: 2.821622295238756e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [24:03<58:11,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 350, Train_loss: 1.1035515088973197e-05, Test_loss: 2.820688502668003e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [27:46<46:44,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400, Train_loss: 1.0849129300956573e-05, Test_loss: 2.8178007612535894e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [31:22<44:44,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 450, Train_loss: 1.0659570280575495e-05, Test_loss: 2.81869081829842e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [34:54<37:30,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500, Train_loss: 1.007626523834701e-05, Test_loss: 2.818024027842432e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 551/1000 [38:33<38:20,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 550, Train_loss: 1.0122339111095404e-05, Test_loss: 2.817959785604392e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [42:15<31:07,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600, Train_loss: 1.035991019628401e-05, Test_loss: 2.8181130306748265e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [46:01<28:37,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 650, Train_loss: 1.0401620003155105e-05, Test_loss: 2.817975744843001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [49:28<22:17,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 700, Train_loss: 9.960209482575439e-06, Test_loss: 2.8180549187501974e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 751/1000 [52:59<18:45,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 750, Train_loss: 1.026673312213354e-05, Test_loss: 2.8181105766347364e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [54:53<02:56,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800, Train_loss: 1.058447290715241e-05, Test_loss: 2.8182594752778594e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [55:32<02:18,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 850, Train_loss: 1.05386611454271e-05, Test_loss: 2.8183885341716457e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [56:13<01:28,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900, Train_loss: 1.037238949078635e-05, Test_loss: 2.8179618758466013e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [56:52<00:43,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 950, Train_loss: 9.803451367213925e-06, Test_loss: 2.8177561226153846e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [57:30<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,14]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        proj = model(x)\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input)\n",
    "#         pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(pred.mean(), y.mean(), pred.std(), y.std())\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            temp_input = x[:,14] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,14]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "#         print(torch.mean((pred-y)**2))\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_, pred_)\n",
    "    l2_error_temp = l2_error(y_, pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Temp: 0.032774762208728124\n",
      "L2 Error  of Temp: 0.0018684054069205104\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Temp: 0.019760469938610074\n",
      "L2 Error  of Temp: 0.0012800967430585063\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.15055359])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
