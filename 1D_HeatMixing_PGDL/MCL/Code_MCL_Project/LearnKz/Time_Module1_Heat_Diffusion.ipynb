{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 14), X_test: (14150, 14)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 1024\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=14, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_diffusion(self, mean=0.0, std=1.0):\n",
    "    \n",
    "    #mean = torch.tensor(mean).to(device)\n",
    "    #std = torch.tensor(std).to(device)\n",
    "    \n",
    "    self = self * std + mean\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = self # temperature profile from previous module output\n",
    "    dt = 3600 # model time step - fixed\n",
    "    dx = 1 # model space step - fixed\n",
    "\n",
    "    # OUTPUT FROM MLP\n",
    "    d = self #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "    j = len(t)\n",
    "    y = np.zeros((len(t), len(t)))\n",
    "\n",
    "    alpha = (dt/dx**2) * d    \n",
    "\n",
    "    az = alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = -alpha # superdiagonal\n",
    "\n",
    "    bz[0] = 1\n",
    "    az[len(az)-2] = 0\n",
    "    bz[len(bz)-1] = 1\n",
    "    cz[0] = 0\n",
    "\n",
    "    # tridiagonal matrix\n",
    "    for k in range(j-1):\n",
    "        y[k][k] = bz[k]\n",
    "        y[k][k+1] = cz[k]\n",
    "        y[k+1][k] = az[k]\n",
    "\n",
    "    y[j-1, j-1] = 1\n",
    "\n",
    "    mn = t * 0.0    \n",
    "    mn[0] = t[0]\n",
    "    mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "    for k in range(1,j-1):\n",
    "        mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    output = np.linalg.solve(y, mn)\n",
    "    \n",
    "    proj = output\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(proj.reshape(-1, 1))\n",
    "\n",
    "    proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.77842326]\n",
      " [ 1.4466805 ]\n",
      " [ 1.27781142]\n",
      " [ 1.10611335]\n",
      " [ 0.93446441]\n",
      " [ 0.76281462]\n",
      " [ 0.59116485]\n",
      " [ 0.41951507]\n",
      " [ 0.24786529]\n",
      " [ 0.07621552]\n",
      " [-0.09543426]\n",
      " [-0.26708403]\n",
      " [-0.43873381]\n",
      " [-0.61038358]\n",
      " [-0.78203336]\n",
      " [-0.95368314]\n",
      " [-1.12533363]\n",
      " [-1.29702428]\n",
      " [-1.47102729]\n",
      " [-1.60033091]]\n"
     ]
    }
   ],
   "source": [
    "proj = implicit_diffusion(np.arange(25, 5, -1))\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(proj.reshape(-1, 1))\n",
    "\n",
    "#scaler.transform(proj.reshape(-1, 1))\n",
    "\n",
    "print(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2692081903.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [121]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pred = torch.tensor(pred, grad_fn=<AddmmBackward0>).float()\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def my_custom_loss(output, target):\n",
    "    pred = implicit_diffusion(output.detach().numpy())\n",
    "    #pred = torch.tensor(pred, requires_grad=True).float()\n",
    "    pred = torch.tensor(pred, grad_fn=<AddmmBackward0>).float() \n",
    "    pred.retain_grad()\n",
    "    #print( pred.grad)\n",
    "    #pred.grad.data.copy_(output.grad.data)\n",
    "    #pred = torch.from_numpy(pred)\n",
    "    \n",
    "    print(pred)\n",
    "    print(target)\n",
    "    loss = (pred - target)\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1481997625.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [122]\u001b[1;36m\u001b[0m\n\u001b[1;33m    tensor([1., 1., 1., 1., 1.], grad_fn=<CloneBackward0>)\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensor([1., 1., 1., 1., 1.], grad_fn=<CloneBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4604e+00],\n",
      "        [-6.3304e-01],\n",
      "        [ 3.6501e-01],\n",
      "        [-1.2058e+00],\n",
      "        [ 1.6849e+00],\n",
      "        [-3.2717e-01],\n",
      "        [-1.3964e-01],\n",
      "        [ 1.4439e+00],\n",
      "        [-2.1284e-02],\n",
      "        [ 3.3486e-01],\n",
      "        [ 9.1337e-01],\n",
      "        [-1.2800e+00],\n",
      "        [-4.2363e-01],\n",
      "        [ 2.1595e-01],\n",
      "        [-7.7214e-01],\n",
      "        [-7.1138e-01],\n",
      "        [-1.0435e+00],\n",
      "        [-9.6928e-01],\n",
      "        [-1.1086e+00],\n",
      "        [-1.8777e-01],\n",
      "        [ 1.8199e-01],\n",
      "        [ 4.5270e-01],\n",
      "        [ 1.3016e+00],\n",
      "        [-7.1354e-01],\n",
      "        [ 9.3957e-01],\n",
      "        [-6.1601e-01],\n",
      "        [-3.5652e-01],\n",
      "        [ 1.8460e+00],\n",
      "        [ 1.0979e+00],\n",
      "        [-1.2885e+00],\n",
      "        [-1.1179e+00],\n",
      "        [-1.0900e+00],\n",
      "        [-9.8784e-01],\n",
      "        [ 6.0133e-01],\n",
      "        [-5.8357e-02],\n",
      "        [-5.2429e-01],\n",
      "        [-2.2694e-01],\n",
      "        [-1.0044e+00],\n",
      "        [ 4.4016e-01],\n",
      "        [-1.2125e+00],\n",
      "        [-8.4534e-01],\n",
      "        [ 3.3412e-01],\n",
      "        [-6.3569e-01],\n",
      "        [-6.9339e-01],\n",
      "        [ 1.4470e+00],\n",
      "        [-7.5348e-01],\n",
      "        [-9.6242e-01],\n",
      "        [ 1.9416e+00],\n",
      "        [-1.0577e+00],\n",
      "        [-7.4374e-01],\n",
      "        [-6.8513e-01],\n",
      "        [-9.0239e-01],\n",
      "        [ 1.3277e-01],\n",
      "        [-7.3415e-01],\n",
      "        [-8.9947e-01],\n",
      "        [ 2.1139e+00],\n",
      "        [-1.1137e+00],\n",
      "        [-1.0609e-01],\n",
      "        [ 6.7008e-01],\n",
      "        [-1.1619e+00],\n",
      "        [ 8.5885e-01],\n",
      "        [-7.5974e-01],\n",
      "        [ 1.1311e-01],\n",
      "        [-1.0272e+00],\n",
      "        [-8.4054e-01],\n",
      "        [-6.7489e-01],\n",
      "        [-8.9978e-01],\n",
      "        [ 8.5113e-02],\n",
      "        [ 8.6065e-01],\n",
      "        [ 7.8692e-02],\n",
      "        [-7.2028e-01],\n",
      "        [-3.9697e-01],\n",
      "        [-1.2126e+00],\n",
      "        [ 4.1788e-01],\n",
      "        [ 1.9832e+00],\n",
      "        [ 2.2305e-01],\n",
      "        [-1.3689e-01],\n",
      "        [ 1.7264e-01],\n",
      "        [ 3.9669e+00],\n",
      "        [-4.8538e-01],\n",
      "        [-4.4290e-02],\n",
      "        [ 5.1738e-01],\n",
      "        [ 1.1871e+00],\n",
      "        [ 5.7657e-01],\n",
      "        [ 2.1629e-01],\n",
      "        [ 1.7164e-01],\n",
      "        [-1.2900e+00],\n",
      "        [ 4.2176e-01],\n",
      "        [-7.0551e-01],\n",
      "        [-4.2528e-02],\n",
      "        [-1.5897e-02],\n",
      "        [ 9.7222e-01],\n",
      "        [-1.2871e+00],\n",
      "        [ 1.4465e+00],\n",
      "        [-5.1672e-01],\n",
      "        [-4.7503e-01],\n",
      "        [-9.7117e-01],\n",
      "        [ 1.0339e-01],\n",
      "        [ 1.0964e+00],\n",
      "        [-8.1174e-01],\n",
      "        [ 8.0719e-01],\n",
      "        [ 2.3971e+00],\n",
      "        [ 5.4616e-01],\n",
      "        [-7.3285e-01],\n",
      "        [-4.8813e-01],\n",
      "        [-7.2904e-01],\n",
      "        [-7.9178e-01],\n",
      "        [-1.3019e+00],\n",
      "        [-1.2879e+00],\n",
      "        [ 8.5655e-01],\n",
      "        [-5.5017e-01],\n",
      "        [ 8.4012e-01],\n",
      "        [ 7.9043e-01],\n",
      "        [ 3.2547e-02],\n",
      "        [-9.9865e-02],\n",
      "        [-1.0737e+00],\n",
      "        [ 5.9579e-01],\n",
      "        [-1.1412e+00],\n",
      "        [ 2.0721e+00],\n",
      "        [-8.9187e-01],\n",
      "        [ 1.3012e+00],\n",
      "        [-1.2016e+00],\n",
      "        [ 3.3205e-01],\n",
      "        [-5.1055e-02],\n",
      "        [ 1.9893e+00],\n",
      "        [-1.0416e+00],\n",
      "        [ 6.4119e-02],\n",
      "        [-6.0340e-01],\n",
      "        [-7.5097e-01],\n",
      "        [ 3.6819e-01],\n",
      "        [-2.9480e-01],\n",
      "        [-1.0013e+00],\n",
      "        [ 3.8898e+00],\n",
      "        [-3.9428e-01],\n",
      "        [-7.1032e-01],\n",
      "        [ 4.8587e-01],\n",
      "        [ 6.4090e-04],\n",
      "        [-2.5123e-01],\n",
      "        [-4.9698e-01],\n",
      "        [ 6.2252e-02],\n",
      "        [ 2.6969e-01],\n",
      "        [ 6.3111e-01],\n",
      "        [ 4.6854e-01],\n",
      "        [ 1.7183e-01],\n",
      "        [ 1.0960e+00],\n",
      "        [ 2.4281e+00],\n",
      "        [-9.8038e-01],\n",
      "        [ 3.1176e-01],\n",
      "        [-3.4907e-01],\n",
      "        [ 1.7195e-01],\n",
      "        [-8.3859e-01],\n",
      "        [-4.1276e-01],\n",
      "        [ 4.7048e-01],\n",
      "        [ 1.2863e+00],\n",
      "        [ 2.4580e-01],\n",
      "        [-1.2882e+00],\n",
      "        [ 9.8181e-01],\n",
      "        [-5.2730e-01],\n",
      "        [-1.2831e+00],\n",
      "        [ 1.9135e+00],\n",
      "        [ 4.3906e-01],\n",
      "        [ 1.5570e+00],\n",
      "        [ 6.1903e-01],\n",
      "        [ 1.3200e+00],\n",
      "        [-7.1280e-01],\n",
      "        [ 8.5219e-01],\n",
      "        [ 1.3902e+00],\n",
      "        [-1.7690e-01],\n",
      "        [ 2.2694e-01],\n",
      "        [-6.8015e-01],\n",
      "        [-4.1195e-01],\n",
      "        [-1.2415e-01],\n",
      "        [-1.2137e+00],\n",
      "        [ 3.7173e-01],\n",
      "        [-3.6554e-01],\n",
      "        [ 3.1217e+00],\n",
      "        [-6.1110e-01],\n",
      "        [-6.6946e-01],\n",
      "        [-1.1021e+00],\n",
      "        [ 9.7413e-01],\n",
      "        [-1.9838e-01],\n",
      "        [-9.1056e-01],\n",
      "        [-1.2985e+00],\n",
      "        [-8.9962e-01],\n",
      "        [ 1.1802e-01],\n",
      "        [-1.8396e-01],\n",
      "        [-1.4734e-01],\n",
      "        [-1.2822e+00],\n",
      "        [-5.7241e-01],\n",
      "        [ 1.9289e+00],\n",
      "        [-3.5192e-01],\n",
      "        [-1.1181e+00],\n",
      "        [ 1.4521e+00],\n",
      "        [ 1.4184e+00],\n",
      "        [-1.5505e-01],\n",
      "        [ 8.2871e-01],\n",
      "        [ 1.3726e-01],\n",
      "        [-1.0273e+00],\n",
      "        [-9.9334e-01],\n",
      "        [ 1.8204e+00],\n",
      "        [-8.2733e-01],\n",
      "        [-1.0834e+00],\n",
      "        [ 6.1666e-01],\n",
      "        [ 2.1773e-02],\n",
      "        [-8.2043e-01],\n",
      "        [ 3.2465e+00],\n",
      "        [-1.0269e+00],\n",
      "        [ 1.9559e-01],\n",
      "        [ 4.0231e-01],\n",
      "        [ 1.6125e-01],\n",
      "        [ 1.8124e+00],\n",
      "        [-8.2222e-01],\n",
      "        [-6.3478e-01],\n",
      "        [-3.3586e-01],\n",
      "        [ 2.7026e-01],\n",
      "        [ 1.0093e+00],\n",
      "        [-2.9858e-01],\n",
      "        [ 9.4752e-01],\n",
      "        [ 3.0673e-01],\n",
      "        [-1.2852e+00],\n",
      "        [-1.1969e+00],\n",
      "        [ 1.2433e+00],\n",
      "        [ 3.5437e-01],\n",
      "        [-9.8371e-01],\n",
      "        [-5.5743e-01],\n",
      "        [-4.2837e-01],\n",
      "        [ 1.9397e+00],\n",
      "        [-9.8806e-02],\n",
      "        [-3.2231e-01],\n",
      "        [ 1.6380e+00],\n",
      "        [ 1.5190e-02],\n",
      "        [ 6.5393e-01],\n",
      "        [ 7.3719e-01],\n",
      "        [-9.4984e-01],\n",
      "        [ 2.1336e-01],\n",
      "        [-7.2238e-01],\n",
      "        [-9.0906e-01],\n",
      "        [-5.2918e-01],\n",
      "        [-5.8355e-01],\n",
      "        [-5.4016e-01],\n",
      "        [-4.9501e-01],\n",
      "        [-1.0600e+00],\n",
      "        [-8.7716e-01],\n",
      "        [ 1.1693e-01],\n",
      "        [-7.2941e-01],\n",
      "        [-1.9842e-01],\n",
      "        [-7.5623e-01],\n",
      "        [-9.5648e-01],\n",
      "        [-1.1316e+00],\n",
      "        [ 6.9347e-02],\n",
      "        [-7.9765e-01],\n",
      "        [-1.0273e+00],\n",
      "        [-3.1040e-01],\n",
      "        [-7.7160e-01],\n",
      "        [-1.0158e+00],\n",
      "        [-3.1196e-01],\n",
      "        [-1.2818e+00],\n",
      "        [-8.4165e-01],\n",
      "        [-6.7984e-01],\n",
      "        [ 1.5301e+00],\n",
      "        [ 2.6862e-01],\n",
      "        [-1.3838e-01],\n",
      "        [ 1.0224e+00],\n",
      "        [-6.1073e-01],\n",
      "        [-1.0998e+00],\n",
      "        [ 2.8244e-01],\n",
      "        [-9.8293e-01],\n",
      "        [-1.1245e+00],\n",
      "        [-1.1186e+00],\n",
      "        [-1.1379e+00],\n",
      "        [-1.0223e+00],\n",
      "        [-1.2864e+00],\n",
      "        [ 4.3331e-01],\n",
      "        [ 2.6407e-01],\n",
      "        [-1.1258e+00],\n",
      "        [ 1.1782e-01],\n",
      "        [ 1.0776e+00],\n",
      "        [-7.1591e-01],\n",
      "        [ 1.9467e+00],\n",
      "        [-7.4403e-01],\n",
      "        [-1.1977e+00],\n",
      "        [ 3.7040e-01],\n",
      "        [-7.2885e-01],\n",
      "        [-1.4209e-01],\n",
      "        [-3.2598e-01],\n",
      "        [ 4.6858e-01],\n",
      "        [-1.0259e+00],\n",
      "        [ 2.1887e-01],\n",
      "        [-6.3114e-01],\n",
      "        [-1.0222e+00],\n",
      "        [ 2.3344e-01],\n",
      "        [-1.2867e+00],\n",
      "        [-1.2911e+00],\n",
      "        [-6.4304e-01],\n",
      "        [ 3.1775e-01],\n",
      "        [ 2.2522e+00],\n",
      "        [-4.1799e-01],\n",
      "        [-3.9505e-01],\n",
      "        [-8.0006e-01],\n",
      "        [ 1.3246e+00],\n",
      "        [-5.2845e-01],\n",
      "        [-1.4490e-02],\n",
      "        [ 1.7764e+00],\n",
      "        [-1.2825e+00],\n",
      "        [ 2.9279e-01],\n",
      "        [-1.2107e+00],\n",
      "        [ 1.0659e+00],\n",
      "        [ 9.5391e-01],\n",
      "        [-2.7939e-01],\n",
      "        [ 7.2715e-01],\n",
      "        [-1.1883e+00],\n",
      "        [ 1.0258e+00],\n",
      "        [-1.4195e-01],\n",
      "        [ 1.4208e+00],\n",
      "        [-9.9242e-01],\n",
      "        [-3.6287e-01],\n",
      "        [ 2.4298e-01],\n",
      "        [ 3.8655e-01],\n",
      "        [ 4.6529e-01],\n",
      "        [ 3.5394e-01],\n",
      "        [ 1.8815e+00],\n",
      "        [-8.0912e-01],\n",
      "        [-5.7234e-01],\n",
      "        [ 2.6039e-01],\n",
      "        [ 8.2161e-01],\n",
      "        [ 2.0288e+00],\n",
      "        [-1.0041e+00],\n",
      "        [ 4.3283e-01],\n",
      "        [ 1.1723e-01],\n",
      "        [-1.2997e-01],\n",
      "        [-4.1253e-01],\n",
      "        [ 1.1423e-01],\n",
      "        [ 2.1625e-01],\n",
      "        [-1.1225e+00],\n",
      "        [ 1.0692e-01],\n",
      "        [-5.7815e-01],\n",
      "        [ 9.3318e-01],\n",
      "        [-1.2847e+00],\n",
      "        [-1.8954e-01],\n",
      "        [-4.2671e-01],\n",
      "        [-1.2041e+00],\n",
      "        [ 1.4285e+00],\n",
      "        [-7.5310e-01],\n",
      "        [-8.7529e-01],\n",
      "        [-1.2832e+00],\n",
      "        [ 2.0958e-02],\n",
      "        [-9.6687e-01],\n",
      "        [ 4.0626e-01],\n",
      "        [-4.2357e-01],\n",
      "        [ 2.6791e-01],\n",
      "        [-8.4928e-01],\n",
      "        [-7.6012e-01],\n",
      "        [-5.9338e-02],\n",
      "        [-8.5921e-01],\n",
      "        [-4.8754e-01],\n",
      "        [-5.4914e-01],\n",
      "        [ 2.0966e+00],\n",
      "        [ 1.0807e-01],\n",
      "        [ 2.4309e+00],\n",
      "        [-3.7367e-02],\n",
      "        [-1.1486e+00],\n",
      "        [-1.2093e+00],\n",
      "        [-1.0197e+00],\n",
      "        [-8.7955e-01],\n",
      "        [-9.9224e-01],\n",
      "        [-8.5518e-01],\n",
      "        [-8.1076e-01],\n",
      "        [ 2.5086e+00],\n",
      "        [-5.0360e-01],\n",
      "        [-1.2905e+00],\n",
      "        [-4.9974e-01],\n",
      "        [-7.6195e-01],\n",
      "        [ 3.9351e-01],\n",
      "        [-2.4097e-01],\n",
      "        [-5.9657e-01],\n",
      "        [ 2.1939e-01],\n",
      "        [-6.1210e-01],\n",
      "        [-6.8088e-01],\n",
      "        [ 5.6122e-01],\n",
      "        [-4.8251e-01],\n",
      "        [-1.0705e+00],\n",
      "        [-8.5860e-02],\n",
      "        [-6.3831e-01],\n",
      "        [-1.0850e+00],\n",
      "        [-4.7567e-01],\n",
      "        [-2.2792e-01],\n",
      "        [-1.1076e+00],\n",
      "        [-3.7646e-01],\n",
      "        [ 1.3033e+00],\n",
      "        [-1.3838e-01],\n",
      "        [ 1.0515e-01],\n",
      "        [-8.1400e-01],\n",
      "        [ 2.2368e-01],\n",
      "        [-4.1089e-01],\n",
      "        [-1.2937e+00],\n",
      "        [ 9.0716e-01],\n",
      "        [ 2.0232e+00],\n",
      "        [ 3.4058e-01],\n",
      "        [-1.2021e+00],\n",
      "        [-7.5567e-02],\n",
      "        [-5.6302e-01],\n",
      "        [-1.2899e+00],\n",
      "        [-7.5247e-01],\n",
      "        [ 9.7819e-01],\n",
      "        [ 2.2201e-02],\n",
      "        [ 2.3529e-01],\n",
      "        [-1.3921e-01],\n",
      "        [-9.1062e-02],\n",
      "        [-5.0299e-01],\n",
      "        [ 3.1158e-01],\n",
      "        [-4.8451e-01],\n",
      "        [-2.4638e-02],\n",
      "        [ 1.4085e+00],\n",
      "        [-1.1670e+00],\n",
      "        [-7.9806e-01],\n",
      "        [ 1.6816e-01],\n",
      "        [-4.4220e-01],\n",
      "        [-1.0909e+00],\n",
      "        [-1.2981e+00],\n",
      "        [ 1.5575e+00],\n",
      "        [ 2.6588e-01],\n",
      "        [ 2.1384e+00],\n",
      "        [-8.2221e-01],\n",
      "        [-5.7031e-01],\n",
      "        [-1.2311e+00],\n",
      "        [ 1.4399e-01],\n",
      "        [-7.2435e-01],\n",
      "        [-1.2828e+00],\n",
      "        [ 2.2997e+00],\n",
      "        [-5.6649e-01],\n",
      "        [-1.6615e-01],\n",
      "        [ 7.4094e-01],\n",
      "        [ 1.0501e+00],\n",
      "        [-1.1386e+00],\n",
      "        [-2.2534e-01],\n",
      "        [-9.2192e-02],\n",
      "        [ 1.4744e+00],\n",
      "        [ 5.2932e-02],\n",
      "        [-2.4852e-01],\n",
      "        [-9.5664e-01],\n",
      "        [ 7.4013e-01],\n",
      "        [ 6.0151e-01],\n",
      "        [-1.9308e-02],\n",
      "        [ 1.3200e-01],\n",
      "        [ 1.3247e+00],\n",
      "        [-8.8339e-01],\n",
      "        [-3.8016e-01],\n",
      "        [-1.0254e+00],\n",
      "        [-1.1144e+00],\n",
      "        [-1.0272e+00],\n",
      "        [-1.5341e-01],\n",
      "        [-4.6199e-01],\n",
      "        [-9.8853e-01],\n",
      "        [ 1.7971e-01],\n",
      "        [-6.8358e-01],\n",
      "        [-8.1805e-01],\n",
      "        [-8.8983e-01],\n",
      "        [-3.3380e-01],\n",
      "        [-1.1535e+00],\n",
      "        [-1.1511e+00],\n",
      "        [ 1.7138e+00],\n",
      "        [ 5.3753e-01],\n",
      "        [-5.1997e-01],\n",
      "        [-1.1580e+00],\n",
      "        [-8.6973e-01],\n",
      "        [ 1.4533e+00],\n",
      "        [-4.1591e-01],\n",
      "        [-1.2822e+00],\n",
      "        [-1.1470e+00],\n",
      "        [ 1.7560e+00],\n",
      "        [-1.1934e+00],\n",
      "        [ 1.0219e-01],\n",
      "        [-6.4042e-01],\n",
      "        [ 1.5295e-01],\n",
      "        [-1.3015e+00],\n",
      "        [ 2.2912e+00],\n",
      "        [-1.0582e-01],\n",
      "        [ 1.9035e+00],\n",
      "        [ 4.2020e-01],\n",
      "        [ 9.2687e-01],\n",
      "        [-3.7744e-01],\n",
      "        [-1.3008e+00],\n",
      "        [-8.7884e-01],\n",
      "        [-4.9690e-01],\n",
      "        [ 1.3532e+00],\n",
      "        [-8.5741e-01],\n",
      "        [ 6.9266e-02],\n",
      "        [-1.6428e-01],\n",
      "        [ 8.6365e-01],\n",
      "        [-1.4682e-01],\n",
      "        [-4.1228e-01],\n",
      "        [-1.2833e+00],\n",
      "        [ 1.0610e+00],\n",
      "        [-1.1517e+00],\n",
      "        [ 2.5512e-01],\n",
      "        [-1.2296e+00],\n",
      "        [ 1.7448e-01],\n",
      "        [ 1.3454e+00],\n",
      "        [-1.1943e+00],\n",
      "        [-1.0066e+00],\n",
      "        [-4.5730e-01],\n",
      "        [ 1.6860e-01],\n",
      "        [ 2.3668e-01],\n",
      "        [-1.2918e+00],\n",
      "        [ 1.2785e+00],\n",
      "        [-9.1535e-01],\n",
      "        [-2.3253e-01],\n",
      "        [-6.6242e-01],\n",
      "        [ 5.5794e-01],\n",
      "        [-9.9755e-01],\n",
      "        [-4.5059e-01],\n",
      "        [-6.7100e-01],\n",
      "        [ 1.4394e-01],\n",
      "        [-6.6829e-01],\n",
      "        [ 3.1791e-01],\n",
      "        [-8.7203e-01],\n",
      "        [-1.1039e+00],\n",
      "        [-1.2021e+00],\n",
      "        [-8.8477e-01],\n",
      "        [-1.5482e-01],\n",
      "        [-5.2376e-01],\n",
      "        [-6.1164e-01],\n",
      "        [ 4.3240e-01],\n",
      "        [-4.2190e-01],\n",
      "        [ 3.4707e+00],\n",
      "        [ 2.3846e-01],\n",
      "        [ 7.2192e-01],\n",
      "        [-5.5687e-01],\n",
      "        [-1.2069e+00],\n",
      "        [ 1.4243e+00],\n",
      "        [ 1.2791e-01],\n",
      "        [-5.4839e-01],\n",
      "        [ 3.0840e-01],\n",
      "        [-3.8910e-01],\n",
      "        [ 1.5194e-01],\n",
      "        [-9.1999e-01],\n",
      "        [-1.2822e+00],\n",
      "        [-1.2215e+00],\n",
      "        [ 1.8191e-01],\n",
      "        [-8.1257e-01],\n",
      "        [-1.2006e+00],\n",
      "        [-1.2020e+00],\n",
      "        [ 7.5076e-01],\n",
      "        [-6.5700e-01],\n",
      "        [-1.2896e+00],\n",
      "        [-7.6136e-01],\n",
      "        [ 8.3376e-01],\n",
      "        [-9.9317e-01],\n",
      "        [ 2.7189e-02],\n",
      "        [-1.2926e+00],\n",
      "        [ 3.1507e-01],\n",
      "        [ 4.0084e-01],\n",
      "        [-9.2634e-01],\n",
      "        [ 5.9948e-01],\n",
      "        [-9.3019e-01],\n",
      "        [ 2.1712e+00],\n",
      "        [ 2.0674e-01],\n",
      "        [ 1.8809e+00],\n",
      "        [-2.7748e-01],\n",
      "        [ 1.0974e+00],\n",
      "        [ 4.6333e-01],\n",
      "        [-1.8526e-01],\n",
      "        [-7.2492e-02],\n",
      "        [-1.1656e+00],\n",
      "        [-1.2258e+00],\n",
      "        [ 1.4143e+00],\n",
      "        [-3.9352e-02],\n",
      "        [-1.2911e+00],\n",
      "        [-9.3913e-01],\n",
      "        [-4.2508e-01],\n",
      "        [-3.4679e-01],\n",
      "        [ 1.5298e-01],\n",
      "        [-8.0192e-01],\n",
      "        [-6.5443e-01],\n",
      "        [-1.2962e+00],\n",
      "        [ 4.2050e-01],\n",
      "        [ 2.4023e+00],\n",
      "        [-2.1975e-03],\n",
      "        [-1.1331e+00],\n",
      "        [-1.2814e+00],\n",
      "        [-1.2235e+00],\n",
      "        [-5.7613e-01],\n",
      "        [-9.4353e-01],\n",
      "        [-4.1851e-01],\n",
      "        [ 1.0871e+00],\n",
      "        [-1.4610e-02],\n",
      "        [ 1.7731e+00],\n",
      "        [-5.3901e-01],\n",
      "        [ 1.7440e+00],\n",
      "        [-2.0733e-02],\n",
      "        [-6.1383e-01],\n",
      "        [-8.6321e-01],\n",
      "        [-1.5081e-01],\n",
      "        [ 4.2083e-01],\n",
      "        [-6.0456e-01],\n",
      "        [ 1.4748e+00],\n",
      "        [-3.7433e-01],\n",
      "        [ 1.1923e+00],\n",
      "        [ 4.1367e-01],\n",
      "        [ 1.8559e+00],\n",
      "        [ 2.0883e+00],\n",
      "        [-8.7120e-01],\n",
      "        [-5.1461e-02],\n",
      "        [-4.9926e-01],\n",
      "        [-1.0124e+00],\n",
      "        [ 3.7381e-01],\n",
      "        [ 9.9877e-01],\n",
      "        [-1.2318e+00],\n",
      "        [ 6.3113e-02],\n",
      "        [ 1.6087e+00],\n",
      "        [-1.0872e+00],\n",
      "        [-1.0243e+00],\n",
      "        [-1.4770e-01],\n",
      "        [ 1.8781e+00],\n",
      "        [-6.7839e-01],\n",
      "        [ 2.5594e-02],\n",
      "        [ 7.1066e-01],\n",
      "        [ 8.2837e-01],\n",
      "        [-2.2348e-01],\n",
      "        [-5.8390e-01],\n",
      "        [ 2.8204e-01],\n",
      "        [-1.2299e+00],\n",
      "        [ 1.3524e+00],\n",
      "        [ 1.3749e-01],\n",
      "        [-1.2962e+00],\n",
      "        [-9.3020e-01],\n",
      "        [-3.5883e-01],\n",
      "        [-4.2753e-01],\n",
      "        [ 1.9511e-01],\n",
      "        [ 5.8846e-01],\n",
      "        [-1.2838e+00],\n",
      "        [-1.1363e+00],\n",
      "        [ 1.4058e+00],\n",
      "        [-5.7923e-01],\n",
      "        [-4.9090e-01],\n",
      "        [ 8.8070e-01],\n",
      "        [-8.6797e-01],\n",
      "        [ 5.7388e-01],\n",
      "        [ 1.8901e-01],\n",
      "        [-7.1749e-01],\n",
      "        [ 4.6205e-01],\n",
      "        [-8.8471e-01],\n",
      "        [-1.2807e-01],\n",
      "        [-6.6104e-01],\n",
      "        [-9.6466e-01],\n",
      "        [-1.2075e+00],\n",
      "        [ 1.8669e-01],\n",
      "        [-4.4153e-01],\n",
      "        [-1.2098e+00],\n",
      "        [ 6.3117e-01],\n",
      "        [ 1.2141e+00],\n",
      "        [-3.9345e-02],\n",
      "        [ 1.5279e+00],\n",
      "        [ 1.2202e+00],\n",
      "        [ 1.6858e-01],\n",
      "        [ 2.1195e+00],\n",
      "        [-1.2216e+00],\n",
      "        [-4.7814e-01],\n",
      "        [-1.0168e+00],\n",
      "        [-3.5484e-02],\n",
      "        [-1.2992e+00],\n",
      "        [-7.6747e-01],\n",
      "        [-3.3757e-01],\n",
      "        [ 5.5904e-01],\n",
      "        [-1.1255e+00],\n",
      "        [ 1.2766e+00],\n",
      "        [-1.2181e+00],\n",
      "        [ 3.7529e-01],\n",
      "        [ 1.7268e+00],\n",
      "        [ 1.5358e-01],\n",
      "        [ 4.0319e-01],\n",
      "        [-1.2605e-01],\n",
      "        [ 2.1286e-01],\n",
      "        [-3.7553e-02],\n",
      "        [-4.2522e-01],\n",
      "        [ 1.1836e-01],\n",
      "        [-9.3500e-01],\n",
      "        [ 1.7428e-01],\n",
      "        [-2.9159e-01],\n",
      "        [-1.0893e+00],\n",
      "        [ 1.5082e+00],\n",
      "        [-1.8005e-02],\n",
      "        [-7.8428e-01],\n",
      "        [ 1.2479e-01],\n",
      "        [-4.1519e-01],\n",
      "        [-1.0784e+00],\n",
      "        [ 1.5896e-01],\n",
      "        [-6.2054e-01],\n",
      "        [-1.1401e+00],\n",
      "        [-9.1105e-01],\n",
      "        [-2.2404e-01],\n",
      "        [-1.4741e-01],\n",
      "        [ 2.0114e+00],\n",
      "        [-8.7111e-01],\n",
      "        [-4.9750e-01],\n",
      "        [ 4.4964e-02],\n",
      "        [-6.7926e-01],\n",
      "        [-4.8297e-01],\n",
      "        [ 4.7825e-02],\n",
      "        [-3.0045e-02],\n",
      "        [-7.0175e-01],\n",
      "        [ 1.8144e-01],\n",
      "        [ 1.8571e+00],\n",
      "        [ 1.1217e-01],\n",
      "        [-7.9917e-01],\n",
      "        [-1.0943e+00],\n",
      "        [-3.7395e-01],\n",
      "        [ 1.0250e+00],\n",
      "        [-1.2882e+00],\n",
      "        [-8.4197e-01],\n",
      "        [-1.0958e+00],\n",
      "        [-2.8229e-02],\n",
      "        [ 1.3840e+00],\n",
      "        [-5.0925e-01],\n",
      "        [-1.1660e-01],\n",
      "        [-5.6509e-01],\n",
      "        [-1.0881e+00],\n",
      "        [ 2.2427e-01],\n",
      "        [-5.2864e-01],\n",
      "        [ 1.4437e+00],\n",
      "        [ 1.7084e+00],\n",
      "        [ 1.1949e+00],\n",
      "        [-1.0871e+00],\n",
      "        [ 3.1194e+00],\n",
      "        [ 1.1506e-01],\n",
      "        [-4.8853e-01],\n",
      "        [ 1.5125e+00],\n",
      "        [ 3.0835e+00],\n",
      "        [ 7.3780e-02],\n",
      "        [-1.2883e+00],\n",
      "        [ 1.1983e+00],\n",
      "        [ 8.5835e-01],\n",
      "        [-1.3026e+00],\n",
      "        [ 1.1445e-01],\n",
      "        [-1.2224e+00],\n",
      "        [ 1.0742e+00],\n",
      "        [ 1.2735e+00],\n",
      "        [ 1.9399e+00],\n",
      "        [-1.9409e-01],\n",
      "        [-1.7591e-01],\n",
      "        [ 1.1009e+00],\n",
      "        [-5.6727e-01],\n",
      "        [ 2.2597e+00],\n",
      "        [ 2.5944e+00],\n",
      "        [-5.8408e-01],\n",
      "        [-1.0291e+00],\n",
      "        [ 2.4838e-01],\n",
      "        [ 7.6612e-01],\n",
      "        [-3.4978e-01],\n",
      "        [ 4.6038e-01],\n",
      "        [ 2.7123e+00],\n",
      "        [-3.7256e-02],\n",
      "        [ 2.2307e+00],\n",
      "        [-1.0176e+00],\n",
      "        [ 3.3286e-01],\n",
      "        [ 1.0140e-01],\n",
      "        [-1.1310e+00],\n",
      "        [-1.2933e+00],\n",
      "        [-4.9404e-01],\n",
      "        [ 9.2100e-02],\n",
      "        [ 1.8195e+00],\n",
      "        [-6.6285e-01],\n",
      "        [ 7.2118e-01],\n",
      "        [-6.9525e-01],\n",
      "        [-9.9199e-01],\n",
      "        [ 1.2107e+00],\n",
      "        [-1.0707e+00],\n",
      "        [ 1.3347e-01],\n",
      "        [-3.6234e-01],\n",
      "        [-6.0386e-01],\n",
      "        [-8.8952e-01],\n",
      "        [-4.5497e-01],\n",
      "        [-3.2769e-01],\n",
      "        [-1.1660e+00],\n",
      "        [-1.4660e-01],\n",
      "        [-3.2883e-01],\n",
      "        [-8.9518e-01],\n",
      "        [-1.1301e+00],\n",
      "        [-8.7869e-01],\n",
      "        [-8.8064e-01],\n",
      "        [-1.0923e+00],\n",
      "        [-7.2586e-01],\n",
      "        [-1.1855e+00],\n",
      "        [ 2.4358e-01],\n",
      "        [-7.3264e-01],\n",
      "        [-8.1876e-01],\n",
      "        [-9.9580e-01],\n",
      "        [-3.2211e-01],\n",
      "        [-1.2917e+00],\n",
      "        [-2.1043e-01],\n",
      "        [-1.2063e+00],\n",
      "        [ 5.0203e-01],\n",
      "        [-4.0299e-01],\n",
      "        [ 8.6821e-01],\n",
      "        [ 7.4266e-02],\n",
      "        [-7.9204e-01],\n",
      "        [ 2.2112e-01],\n",
      "        [ 1.8768e+00],\n",
      "        [ 1.9338e+00],\n",
      "        [-1.1315e+00],\n",
      "        [-6.6777e-01],\n",
      "        [-8.6850e-02],\n",
      "        [-2.3922e-01],\n",
      "        [-1.0506e+00],\n",
      "        [ 1.5009e-01],\n",
      "        [ 1.3293e-01],\n",
      "        [-8.8250e-01],\n",
      "        [-4.1854e-01],\n",
      "        [-1.1895e+00],\n",
      "        [-1.0514e+00],\n",
      "        [ 2.0123e+00],\n",
      "        [-5.3741e-02],\n",
      "        [ 2.5930e-01],\n",
      "        [ 1.8795e+00],\n",
      "        [ 1.6745e+00],\n",
      "        [-6.3783e-01],\n",
      "        [-8.9273e-01],\n",
      "        [-1.1401e+00],\n",
      "        [ 6.0573e-01],\n",
      "        [-1.4149e-01],\n",
      "        [-1.0854e+00],\n",
      "        [-1.2290e+00],\n",
      "        [-8.0232e-01],\n",
      "        [-1.0143e+00],\n",
      "        [-1.2341e+00],\n",
      "        [ 3.0956e+00],\n",
      "        [ 8.4884e-01],\n",
      "        [-9.1782e-01],\n",
      "        [ 2.1475e-01],\n",
      "        [-1.2854e+00],\n",
      "        [ 2.8782e-01],\n",
      "        [-2.1969e-01],\n",
      "        [-6.0257e-01],\n",
      "        [-9.5985e-01],\n",
      "        [ 1.1802e-01],\n",
      "        [-1.0263e+00],\n",
      "        [-7.7727e-01],\n",
      "        [-4.7579e-01],\n",
      "        [-3.0289e-01],\n",
      "        [-1.4486e-01],\n",
      "        [-3.1398e-01],\n",
      "        [-1.6864e-01],\n",
      "        [-5.0846e-01],\n",
      "        [-5.2915e-01],\n",
      "        [-3.1306e-01],\n",
      "        [ 7.1503e-01],\n",
      "        [ 1.9489e+00],\n",
      "        [ 1.0112e+00],\n",
      "        [ 1.7118e-01],\n",
      "        [ 1.7539e+00],\n",
      "        [ 1.4449e+00],\n",
      "        [ 1.2959e+00],\n",
      "        [ 1.7955e+00],\n",
      "        [-4.6671e-01],\n",
      "        [-9.5700e-01],\n",
      "        [ 9.3857e-02],\n",
      "        [-1.2936e+00],\n",
      "        [-1.2857e+00],\n",
      "        [-1.1316e+00],\n",
      "        [-1.0223e+00],\n",
      "        [-1.8042e-01],\n",
      "        [-1.0967e+00],\n",
      "        [-1.2974e+00],\n",
      "        [-2.4946e-01],\n",
      "        [-4.7505e-01],\n",
      "        [ 1.1628e+00],\n",
      "        [ 8.1812e-02],\n",
      "        [ 8.9487e-01],\n",
      "        [-1.2821e+00],\n",
      "        [-2.0873e-01],\n",
      "        [-8.6914e-01],\n",
      "        [-1.0957e+00],\n",
      "        [-1.1984e+00],\n",
      "        [-3.7258e-01],\n",
      "        [ 1.8029e+00],\n",
      "        [-7.8655e-01],\n",
      "        [-3.0045e-01],\n",
      "        [ 3.5800e+00],\n",
      "        [ 1.1159e+00],\n",
      "        [ 1.8795e+00],\n",
      "        [ 7.9345e-02],\n",
      "        [ 7.1872e-01],\n",
      "        [ 1.0173e+00],\n",
      "        [-2.5980e-01],\n",
      "        [-4.6864e-01],\n",
      "        [ 5.3617e-01],\n",
      "        [-1.4159e-01],\n",
      "        [ 1.4033e+00],\n",
      "        [ 1.0951e+00],\n",
      "        [ 3.7272e-01],\n",
      "        [-9.1553e-01],\n",
      "        [ 2.5448e-01],\n",
      "        [ 8.6390e-01],\n",
      "        [-9.3508e-01],\n",
      "        [-1.3575e-01],\n",
      "        [ 1.4632e-01],\n",
      "        [-8.4482e-01],\n",
      "        [ 1.3760e+00],\n",
      "        [ 1.6972e+00],\n",
      "        [-1.5984e-02],\n",
      "        [-1.0256e+00],\n",
      "        [ 2.9619e-01],\n",
      "        [ 3.3662e-01],\n",
      "        [-1.0206e+00],\n",
      "        [ 4.0157e-01],\n",
      "        [ 6.4944e-01],\n",
      "        [ 8.3202e-02],\n",
      "        [-8.9486e-01],\n",
      "        [ 6.1122e-01],\n",
      "        [-8.2738e-01],\n",
      "        [-4.7879e-01],\n",
      "        [-1.1934e+00],\n",
      "        [-6.2066e-01],\n",
      "        [-2.9402e-02],\n",
      "        [ 5.3342e-01],\n",
      "        [-1.1059e+00],\n",
      "        [-9.5307e-01],\n",
      "        [-3.4278e-01],\n",
      "        [ 2.1382e-01],\n",
      "        [-5.0408e-02],\n",
      "        [-5.0603e-02],\n",
      "        [-1.1911e+00],\n",
      "        [ 5.0931e-01],\n",
      "        [-4.7182e-01],\n",
      "        [-1.0883e+00],\n",
      "        [ 1.8184e+00],\n",
      "        [ 1.6662e-01],\n",
      "        [-6.6787e-01],\n",
      "        [-3.3871e-02],\n",
      "        [-5.9444e-01],\n",
      "        [ 1.0555e+00],\n",
      "        [-4.5390e-01],\n",
      "        [-7.7305e-01],\n",
      "        [-2.4643e-01],\n",
      "        [-3.4952e-01],\n",
      "        [ 1.8126e+00],\n",
      "        [ 6.8819e-01],\n",
      "        [ 1.3248e+00],\n",
      "        [-9.9753e-01],\n",
      "        [ 9.7151e-01],\n",
      "        [ 2.1076e+00],\n",
      "        [ 1.7311e+00],\n",
      "        [ 5.0263e-01],\n",
      "        [-1.1992e+00],\n",
      "        [ 1.7388e+00],\n",
      "        [ 1.9402e+00],\n",
      "        [ 1.0898e+00],\n",
      "        [ 2.9154e-01],\n",
      "        [ 2.1669e+00],\n",
      "        [-1.0987e+00],\n",
      "        [-7.0693e-01],\n",
      "        [ 5.7568e-01],\n",
      "        [-3.2793e-01],\n",
      "        [ 2.1896e+00],\n",
      "        [-8.4223e-01],\n",
      "        [-4.1972e-01],\n",
      "        [-1.2942e+00],\n",
      "        [-1.2213e+00],\n",
      "        [-1.2316e+00],\n",
      "        [-8.9765e-01],\n",
      "        [ 1.2940e+00],\n",
      "        [-1.0754e+00],\n",
      "        [-1.1001e+00],\n",
      "        [-8.4359e-01],\n",
      "        [-1.3404e-01],\n",
      "        [-1.1566e+00],\n",
      "        [ 4.9420e-01],\n",
      "        [ 2.7165e+00],\n",
      "        [-7.7700e-01],\n",
      "        [-1.0141e+00],\n",
      "        [ 7.5004e-01],\n",
      "        [-1.5366e-01],\n",
      "        [-9.9388e-01],\n",
      "        [-9.9371e-01],\n",
      "        [-8.8297e-01],\n",
      "        [ 1.6925e+00],\n",
      "        [ 2.8959e-01],\n",
      "        [-3.4340e-01],\n",
      "        [-1.2943e+00],\n",
      "        [ 2.9203e-01],\n",
      "        [ 1.4711e+00],\n",
      "        [-9.0903e-01],\n",
      "        [-1.0596e-01],\n",
      "        [-3.7328e-01],\n",
      "        [ 5.9947e-01],\n",
      "        [ 2.2294e+00],\n",
      "        [-1.1983e+00],\n",
      "        [ 4.6674e-01],\n",
      "        [-3.1500e-01],\n",
      "        [ 1.3568e+00],\n",
      "        [ 2.2662e+00],\n",
      "        [-1.2911e+00],\n",
      "        [-9.3565e-01],\n",
      "        [ 1.8232e+00],\n",
      "        [ 2.0950e+00],\n",
      "        [-7.8948e-02],\n",
      "        [-8.6534e-01],\n",
      "        [ 1.1291e+00],\n",
      "        [-5.3041e-01],\n",
      "        [ 8.8078e-02],\n",
      "        [ 7.0368e-02],\n",
      "        [ 5.6524e-02],\n",
      "        [-1.1083e+00],\n",
      "        [ 8.6450e-02],\n",
      "        [-1.0058e+00],\n",
      "        [-5.3090e-02],\n",
      "        [ 1.0489e+00],\n",
      "        [ 4.7390e-01],\n",
      "        [-4.1701e-01],\n",
      "        [-5.3958e-02],\n",
      "        [-6.7753e-01],\n",
      "        [-1.0989e+00],\n",
      "        [-1.1868e+00],\n",
      "        [ 4.9080e-01],\n",
      "        [-1.2267e+00],\n",
      "        [ 1.4093e+00],\n",
      "        [-6.5695e-01],\n",
      "        [ 8.2951e-01],\n",
      "        [ 3.7583e-01],\n",
      "        [-8.4404e-01],\n",
      "        [-8.5644e-01],\n",
      "        [-8.7224e-01],\n",
      "        [ 2.1549e-02],\n",
      "        [ 2.8297e-01]], grad_fn=<AddmmBackward0>)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(proj) \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# pred = implicit_diffusion(proj.detach().numpy())\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# pred = model(x)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# pred = torch.from_numpy(pred)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# loss = criterion(pred, y)\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmy_custom_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[1;32mIn [111]\u001b[0m, in \u001b[0;36mmy_custom_loss\u001b[1;34m(output, target)\u001b[0m\n\u001b[0;32m      4\u001b[0m pred\u001b[38;5;241m.\u001b[39mretain_grad()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m( pred\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m(output\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#pred = torch.from_numpy(pred)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy_'"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        #print(model(x))\n",
    "        proj = model(x)\n",
    "        \n",
    "        # torch.set_printoptions(profile=\"full\")\n",
    "        print(proj) \n",
    "        \n",
    "        # pred = implicit_diffusion(proj.detach().numpy())\n",
    "        # pred = model(x)\n",
    "        # pred = torch.from_numpy(pred)\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        # pred.grad.data.copy_(proj.grad.data)\n",
    "        \n",
    "        # proj[0:30,0] = pred\n",
    "        \n",
    "        # print(proj)\n",
    "\n",
    "        # loss = criterion(pred, y)\n",
    "        loss = my_custom_loss(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            pred = model(x)\n",
    "            #proj = model(x)\n",
    "            #pred = implicit_diffusion(proj.detach().numpy())\n",
    "            #pred = torch.from_numpy(pred)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_[:,0])\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_[:,0])\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rmse of Diffusivity: 9.859477536592607e-06\n",
      "Test Rmse of Temp: 0.7826148693716032\n",
      "L2 Error of Diffusivity: 0.4382787878287092\n",
      "L2 Error  of Temp: 0.053899259632144064\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rmse of Diffusivity: 1.407105732980103e-06\n",
      "Train Rmse of Temp: 0.06460328518966645\n",
      "L2 Error of Diffusivity: 0.06055042984845283\n",
      "L2 Error  of Temp: 0.005046837794778314\n"
     ]
    }
   ],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.07829505e-05, 1.13460421e+01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
