{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", init=\"xavier\"):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = torch.nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = torch.nn.Tanh()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = torch.nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unspecified activation type\")\n",
    "        \n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "        if init==\"xavier\":\n",
    "            self.xavier_init_weights()\n",
    "        elif init==\"kaiming\":\n",
    "            self.kaiming_init_weights()\n",
    "    \n",
    "    def xavier_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Xavier Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def kaiming_init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            print(\"Initializing Network with Kaiming Initialization..\")\n",
    "            for m in self.layers.modules():\n",
    "                if hasattr(m, 'weight'):\n",
    "                    nn.init.kaiming_uniform_(m.weight)\n",
    "                    m.bias.data.fill_(0.0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>AirTemp_degC</th>\n",
       "      <th>Longwave_Wm-2</th>\n",
       "      <th>Latent_Wm-2</th>\n",
       "      <th>Sensible_Wm-2</th>\n",
       "      <th>Shortwave_Wm-2</th>\n",
       "      <th>lightExtinct_m-1</th>\n",
       "      <th>ShearVelocity_mS-1</th>\n",
       "      <th>ShearStress_Nm-2</th>\n",
       "      <th>Area_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>buoyancy</th>\n",
       "      <th>diffusivity</th>\n",
       "      <th>temp_heat00</th>\n",
       "      <th>temp_diff01</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp_mix02</th>\n",
       "      <th>temp_conv03</th>\n",
       "      <th>obs_temp</th>\n",
       "      <th>input_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>11.467275</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.409</td>\n",
       "      <td>16.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.627332</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.545011</td>\n",
       "      <td>11.570472</td>\n",
       "      <td>16.480</td>\n",
       "      <td>16.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.650008</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.631393</td>\n",
       "      <td>11.575860</td>\n",
       "      <td>16.130</td>\n",
       "      <td>16.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>11.394500</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>11.393058</td>\n",
       "      <td>15.827</td>\n",
       "      <td>15.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.715021</td>\n",
       "      <td>678.292163</td>\n",
       "      <td>-152.775961</td>\n",
       "      <td>-4.194743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255324</td>\n",
       "      <td>1.085796</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>11.123803</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>11.130929</td>\n",
       "      <td>16.270</td>\n",
       "      <td>16.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35370</th>\n",
       "      <td>21</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>6.772435</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>6.773650</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35371</th>\n",
       "      <td>22</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.995879</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>5.996763</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35372</th>\n",
       "      <td>23</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>5.229508</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>5.230045</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35373</th>\n",
       "      <td>24</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.467800</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>4.468109</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35374</th>\n",
       "      <td>25</td>\n",
       "      <td>13.595026</td>\n",
       "      <td>718.547070</td>\n",
       "      <td>-230.901096</td>\n",
       "      <td>-40.903561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.069661</td>\n",
       "      <td>2.343012</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>3.708436</td>\n",
       "      <td>12.204</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35375 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth  AirTemp_degC  Longwave_Wm-2  Latent_Wm-2  Sensible_Wm-2  \\\n",
       "0          1     10.715021     678.292163  -152.775961      -4.194743   \n",
       "1          2     10.715021     678.292163  -152.775961      -4.194743   \n",
       "2          3     10.715021     678.292163  -152.775961      -4.194743   \n",
       "3          4     10.715021     678.292163  -152.775961      -4.194743   \n",
       "4          5     10.715021     678.292163  -152.775961      -4.194743   \n",
       "...      ...           ...            ...          ...            ...   \n",
       "35370     21     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35371     22     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35372     23     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35373     24     13.595026     718.547070  -230.901096     -40.903561   \n",
       "35374     25     13.595026     718.547070  -230.901096     -40.903561   \n",
       "\n",
       "       Shortwave_Wm-2  lightExtinct_m-1  ShearVelocity_mS-1  ShearStress_Nm-2  \\\n",
       "0                 0.0          0.255324            1.085796          0.002290   \n",
       "1                 0.0          0.255324            1.085796          0.002290   \n",
       "2                 0.0          0.255324            1.085796          0.002290   \n",
       "3                 0.0          0.255324            1.085796          0.002290   \n",
       "4                 0.0          0.255324            1.085796          0.002290   \n",
       "...               ...               ...                 ...               ...   \n",
       "35370             0.0          2.069661            2.343012          0.007849   \n",
       "35371             0.0          2.069661            2.343012          0.007849   \n",
       "35372             0.0          2.069661            2.343012          0.007849   \n",
       "35373             0.0          2.069661            2.343012          0.007849   \n",
       "35374             0.0          2.069661            2.343012          0.007849   \n",
       "\n",
       "          Area_m2  ...  buoyancy  diffusivity  temp_heat00  temp_diff01  \\\n",
       "0      36000000.0  ...  0.000000     0.000037    11.467275    11.467275   \n",
       "1      36000000.0  ...  0.000000     0.000037    11.650008    11.627332   \n",
       "2      36000000.0  ...  0.000271     0.000021    11.650008    11.631393   \n",
       "3      36000000.0  ...  0.000278     0.000021    11.394500    11.393058   \n",
       "4      36000000.0  ...  0.000185     0.000024    11.123803    11.130929   \n",
       "...           ...  ...       ...          ...          ...          ...   \n",
       "35370  36000000.0  ...  0.000282     0.000020     6.772435     6.773650   \n",
       "35371  36000000.0  ...  0.000191     0.000024     5.995879     5.996763   \n",
       "35372  36000000.0  ...  0.000102     0.000032     5.229508     5.230045   \n",
       "35373  36000000.0  ...  0.000013     0.000037     4.467800     4.468109   \n",
       "35374  36000000.0  ...  0.000013     0.000037     3.708436     3.708436   \n",
       "\n",
       "       day_of_year  time_of_day  temp_mix02  temp_conv03  obs_temp  input_obs  \n",
       "0              155            1   11.545011    11.570472    16.409     16.350  \n",
       "1              155            1   11.545011    11.570472    16.480     16.426  \n",
       "2              155            1   11.631393    11.575860    16.130     16.088  \n",
       "3              155            1   11.393058    11.393058    15.827     15.789  \n",
       "4              155            1   11.130929    11.130929    16.270     16.240  \n",
       "...            ...          ...         ...          ...       ...        ...  \n",
       "35370          213           23    6.773650     6.773650    12.204     12.204  \n",
       "35371          213           23    5.996763     5.996763    12.204     12.204  \n",
       "35372          213           23    5.230045     5.230045    12.204     12.204  \n",
       "35373          213           23    4.468109     4.468109    12.204     12.204  \n",
       "35374          213           23    3.708436     3.708436    12.204     12.204  \n",
       "\n",
       "[35375 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"all_data_lake_modeling_in_time_wHeat.csv\")\n",
    "data_df = data_df.drop(columns=['time'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days total: 1415\n",
      "Number of training points: 21225\n"
     ]
    }
   ],
   "source": [
    "training_frac = 0.60\n",
    "depth_steps = 25\n",
    "number_days = len(data_df)//depth_steps\n",
    "n_obs = int(number_days*training_frac)*depth_steps\n",
    "print(f\"Number of days total: {number_days}\")\n",
    "print(f\"Number of training points: {n_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21225, 22)\n",
      "[10.71502075 10.71502075 10.71502075 ... 16.69999084 16.69999084\n",
      " 16.69999084]\n",
      "(21225,)\n"
     ]
    }
   ],
   "source": [
    "data = data_df.values\n",
    "\n",
    "train_data = data[:n_obs]\n",
    "test_data = data[n_obs:]\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_data[:,1])\n",
    "print(train_data[:,0].shape)\n",
    "\n",
    "#performing normalization on all the columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Heat Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['depth', 'AirTemp_degC', 'Longwave_Wm-2', 'Latent_Wm-2', 'Sensible_Wm-2', 'Shortwave_Wm-2',\n",
    "                'lightExtinct_m-1', 'ShearVelocity_mS-1', 'ShearStress_Nm-2', 'Area_m2', \n",
    "                 'buoyancy', 'day_of_year', 'time_of_day', 'temp_heat00', 'diffusivity']\n",
    "output_columns = ['temp_diff01']\n",
    "\n",
    "input_column_ix = [data_df.columns.get_loc(column) for column in input_columns]\n",
    "output_column_ix = [data_df.columns.get_loc(column) for column in output_columns]\n",
    "\n",
    "X_train, X_test = train_data[:,input_column_ix], test_data[:,input_column_ix]\n",
    "y_train, y_test = train_data[:,output_column_ix], test_data[:,output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.66410059 -1.52542554 -1.38675049 ...  1.38675049  1.52542554\n",
      "  1.66410059]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21225, 15), X_test: (14150, 15)\n",
      "y_train: (21225, 1), y_test: (14150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping track of the mean and standard deviations\n",
    "train_mean = scaler.mean_\n",
    "train_std = scaler.scale_\n",
    "\n",
    "input_mean, input_std = train_mean[input_column_ix], train_std[input_column_ix]\n",
    "output_mean, output_std = train_mean[output_column_ix], train_std[output_column_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "batch_size = 25\n",
    "train_dataset = DataGenerator(X_train, y_train)\n",
    "test_dataset = DataGenerator(X_test, y_test)\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Network with Xavier Initialization..\n"
     ]
    }
   ],
   "source": [
    "layers = [X_train.shape[-1], 32, 32, y_train.shape[-1]]\n",
    "\n",
    "model = MLP(layers, activation=\"gelu\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "decay_rate = 0.1\n",
    "decay_steps = 500\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                         betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU()\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Linear(in_features=15, out_features=32, bias=True)\n",
      "    (activation_0): GELU()\n",
      "    (layer_1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (activation_1): GELU()\n",
      "    (layer_2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_diffusion(diff, temp, mean, std, mean2, std2):\n",
    "    \n",
    "    #mean = torch.tensor(mean).to(device)\n",
    "    # std = torch.tensor(std).to(device)\n",
    "    mean_diff = torch.tensor(mean[input_column_ix[13]]).to(device)\n",
    "    std_diff = torch.tensor(std[input_column_ix[13]]).to(device)\n",
    "    \n",
    "    mean_temp = torch.tensor(mean[input_column_ix[14]]).to(device)\n",
    "    std_temp = torch.tensor(std[input_column_ix[14]]).to(device)\n",
    "    \n",
    "    mean_out = torch.tensor(mean2).to(device)\n",
    "    std_out = torch.tensor(std2).to(device)\n",
    "    \n",
    "    # de-normalise data\n",
    "    diff = diff * std_diff + mean_diff\n",
    "    print(\"diff:\", diff)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "    t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "    print(\"t:\", t)\n",
    "    \n",
    "    dt = 3600 # model time step - fixed\n",
    "    dx = 1 # model space step - fixed\n",
    "\n",
    "    # OUTPUT FROM MLP\n",
    "    d = diff #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "    j = len(t)\n",
    "    y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "    alpha = (dt/dx**2) * d    \n",
    "\n",
    "    az = alpha # subdiagonal\n",
    "    bz = 2 * (1 + alpha) # diagonal\n",
    "    cz = -alpha # superdiagonal\n",
    "\n",
    "    bz[0] = 1\n",
    "    az[len(az)-2] = 0\n",
    "    bz[len(bz)-1] = 1\n",
    "    cz[0] = 0\n",
    "\n",
    "    # tridiagonal matrix\n",
    "    for k in range(j-1):\n",
    "        y[k][k] = bz[k]\n",
    "        y[k][k+1] = cz[k]\n",
    "        y[k+1][k] = az[k]\n",
    "\n",
    "    y[j-1, j-1] = 1\n",
    "\n",
    "    mn = t * 0.0    \n",
    "    mn[0] = t[0]\n",
    "    mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "    for k in range(1,j-1):\n",
    "        mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "    print(y.dtype, mn.dtype)\n",
    "    output = torch.linalg.solve(y, mn)\n",
    "    \n",
    "    proj = output\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(proj.reshape(-1, 1))\n",
    "    # scaler.fit(proj)\n",
    "    \n",
    "    # normalise data back\n",
    "    #proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    # proj = scaler.transform(proj)\n",
    "    mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "    proj = (proj-mean_out)/std_out\n",
    "\n",
    "    proj = proj.to(torch.double)\n",
    "\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 17, 14, 13]\n",
      "[ 1.30000000e+01  1.93619387e+01  7.97611281e+02 -1.27637027e+02\n",
      " -1.68297160e+01  2.36993670e+02  4.08006076e-01  2.30560213e+00\n",
      "  8.82174601e-03  3.60000000e+07  8.40535870e-04  1.72232038e+02\n",
      "  1.14310954e+01  1.13445025e+01  2.07829505e-05]\n",
      "2.0782950512289867e-05\n",
      "[11.34604205]\n"
     ]
    }
   ],
   "source": [
    "print(input_column_ix)\n",
    "print(input_mean)\n",
    "print(input_mean[input_column_ix[13]])\n",
    "print(output_mean)\n",
    "#print(torch.tensor(input_mean[input_column_ix][14]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusivity_true = torch.tensor(X_train[:,input_column_ix[13]], device=device).unsqueeze(1)\n",
    "temp_heat_true = torch.tensor(X_train[:,input_column_ix[14]], device=device)#.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0783e-05, dtype=torch.float64) tensor(1.0397e-05, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "mean_diff = torch.tensor(input_mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(input_std[input_column_ix[13]]).to(device)\n",
    "print(mean_diff, std_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7190e-05],\n",
       "        [3.7190e-05],\n",
       "        [2.0770e-05],\n",
       "        ...,\n",
       "        [3.7190e-05],\n",
       "        [3.7190e-05],\n",
       "        [3.7190e-05]], dtype=torch.float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusivity_true*std_diff+mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: tensor([[3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [2.0770e-05],\n",
      "        [2.0541e-05],\n",
      "        [2.4498e-05],\n",
      "        [2.8890e-05],\n",
      "        [3.1367e-05],\n",
      "        [2.9106e-05],\n",
      "        [2.2591e-05],\n",
      "        [1.7295e-05],\n",
      "        [1.7028e-05],\n",
      "        [1.7991e-05],\n",
      "        [1.9071e-05],\n",
      "        [2.0154e-05],\n",
      "        [2.1378e-05],\n",
      "        [2.2856e-05],\n",
      "        [2.4662e-05],\n",
      "        [2.6884e-05],\n",
      "        [2.9676e-05],\n",
      "        [3.3355e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05]], dtype=torch.float64)\n",
      "t: tensor([11.4673, 11.6500, 11.6500, 11.3945, 11.1238, 10.9389, 10.8103, 10.7024,\n",
      "        10.5719, 10.3305,  9.8574,  9.3268,  8.8159,  8.3246,  7.8447,  7.3750,\n",
      "         6.9170,  6.4724,  6.0415,  5.6232,  5.2154,  4.8159,  4.4228,  4.0340],\n",
      "       dtype=torch.float64)\n",
      "torch.float64 torch.float64\n"
     ]
    }
   ],
   "source": [
    "pred = implicit_diffusion(diff=diffusivity_true[0:24,], \n",
    "                          temp=temp_heat_true[0:24], \n",
    "                          mean=input_mean, \n",
    "                          std=input_std,\n",
    "                          mean2=output_mean, \n",
    "                          std2=output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: tensor([[3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [2.4034e-05],\n",
      "        [2.0824e-05],\n",
      "        [2.4411e-05],\n",
      "        [2.8554e-05],\n",
      "        [3.0794e-05],\n",
      "        [2.8513e-05],\n",
      "        [2.2408e-05],\n",
      "        [1.7468e-05],\n",
      "        [1.7097e-05],\n",
      "        [1.7992e-05],\n",
      "        [1.9061e-05],\n",
      "        [2.0151e-05],\n",
      "        [2.1380e-05],\n",
      "        [2.2857e-05],\n",
      "        [2.4661e-05],\n",
      "        [2.6878e-05],\n",
      "        [2.9665e-05],\n",
      "        [3.3338e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05],\n",
      "        [3.7190e-05]], dtype=torch.float64)\n",
      "t: tensor([11.3815, 11.5705, 11.5759, 11.3931, 11.1309, 10.9446, 10.8125, 10.6999,\n",
      "        10.5629, 10.3166,  9.8537,  9.3279,  8.8172,  8.3254,  7.8455,  7.3759,\n",
      "         6.9182,  6.4737,  6.0429,  5.6245,  5.2165,  4.8168,  4.4235,  4.0343],\n",
      "       dtype=torch.float64)\n",
      "torch.float64 torch.float64\n",
      "tensor([11.3815, 10.1381, 10.4490, 10.5429, 10.2821,  9.9784,  9.7609,  9.6690,\n",
      "         9.6794,  9.6203,  9.2648,  8.7597,  8.2511,  7.7613,  7.2841,  6.8156,\n",
      "         6.3560,  5.9060,  5.4651,  5.0305,  4.6081,  4.2292,  3.8896,  4.0343],\n",
      "       dtype=torch.float64)\n",
      "tensor([ 0.0060, -0.2038, -0.1514, -0.1355, -0.1795, -0.2308, -0.2675, -0.2830,\n",
      "        -0.2812, -0.2912, -0.3512, -0.4364, -0.5222, -0.6048, -0.6854, -0.7644,\n",
      "        -0.8420, -0.9179, -0.9923, -1.0656, -1.1369, -1.2008, -1.2581, -1.2337],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "diff=diffusivity_true[25:49,]\n",
    "temp=temp_heat_true[25:49]\n",
    "mean=input_mean\n",
    "std=input_std\n",
    "mean2=output_mean\n",
    "std2=output_std\n",
    "\n",
    "mean_diff = torch.tensor(mean[input_column_ix[13]]).to(device)\n",
    "std_diff = torch.tensor(std[input_column_ix[13]]).to(device)\n",
    "    \n",
    "mean_temp = torch.tensor(mean[input_column_ix[14]]).to(device)\n",
    "std_temp = torch.tensor(std[input_column_ix[14]]).to(device)\n",
    "    \n",
    "mean_out = torch.tensor(mean2).to(device)\n",
    "std_out = torch.tensor(std2).to(device)\n",
    "    \n",
    "    # de-normalise data\n",
    "diff = diff * std_diff + mean_diff\n",
    "print(\"diff:\", diff)\n",
    "    \n",
    "    # INPUT DATA FROM PREVIOUS MODULE\n",
    "t = temp * std_temp + mean_temp # temperature profile from previous module output\n",
    "print(\"t:\", t)\n",
    "    \n",
    "dt = 3600 # model time step - fixed\n",
    "dx = 1 # model space step - fixed\n",
    "\n",
    "# OUTPUT FROM MLP\n",
    "d = diff #np.array([1e-5] * len(t)) # estimated diffusivity values\n",
    "\n",
    "    # IMPLEMENTATION OF CRANK-NICHOLSON SCHEME\n",
    "j = len(t)\n",
    "y = torch.zeros((len(t), len(t)), dtype=torch.float64).to(device)\n",
    "\n",
    "alpha = (dt/dx**2) * d    \n",
    "\n",
    "az = alpha # subdiagonal\n",
    "bz = 2 * (1 + alpha) # diagonal\n",
    "cz = -alpha # superdiagonal\n",
    "\n",
    "bz[0] = 1\n",
    "az[len(az)-2] = 0\n",
    "bz[len(bz)-1] = 1\n",
    "cz[0] = 0\n",
    "\n",
    "    # tridiagonal matrix\n",
    "for k in range(j-1):\n",
    "    y[k][k] = bz[k]\n",
    "    y[k][k+1] = cz[k]\n",
    "    y[k+1][k] = az[k]\n",
    "\n",
    "y[j-1, j-1] = 1\n",
    "\n",
    "mn = t * 0.0    \n",
    "mn[0] = t[0]\n",
    "mn[len(mn)-1] = t[len(t)-1]\n",
    "\n",
    "for k in range(1,j-1):\n",
    "    mn[k] = alpha[k] * t[k-1] + 2 * (1 - alpha[k]) * t[k] + alpha[k] * t[k]\n",
    "\n",
    "    # DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\n",
    "print(y.dtype, mn.dtype)\n",
    "output = torch.linalg.solve(y, mn)\n",
    "    \n",
    "proj = output\n",
    "\n",
    "print(proj)\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(proj.reshape(-1, 1))\n",
    "    # scaler.fit(proj)\n",
    "    \n",
    "    # normalise data back\n",
    "    #proj = scaler.transform(proj.reshape(-1, 1))\n",
    "    # proj = scaler.transform(proj)\n",
    "mean, std, var = torch.mean(proj), torch.std(proj), torch.var(proj)\n",
    "proj = (proj-mean_out)/std_out\n",
    "\n",
    "proj = proj.to(torch.double)\n",
    "    \n",
    "print(proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21225])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_heat_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0205, -0.1915, -0.1305, -0.1251, -0.1804, -0.2329, -0.2703, -0.2856,\n",
       "        -0.2817, -0.2890, -0.3499, -0.4364, -0.5224, -0.6050, -0.6855, -0.7646,\n",
       "        -0.8421, -0.9181, -0.9925, -1.0658, -1.1371, -1.2009, -1.2582, -1.2337],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02045524],\n",
       "       [ 0.0474611 ],\n",
       "       [ 0.0481462 ],\n",
       "       ...,\n",
       "       [-1.08580659],\n",
       "       [-1.18739254],\n",
       "       [-1.28866616]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x221f6a90130>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred.numpy(),y_train[0:24,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the Crank-Nicholson scheme works\n",
    "\n",
    "# temp = torch.rand(5,1).to(device)\n",
    "# diff = torch.rand(5,1).to(device)\n",
    "# print(temp), print(diff)\n",
    "# implicit_diffusion(diff, temp, input_mean, input_std,\n",
    "#                                  output_mean, output_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "tensor([ 1.8213,  0.3093,  2.7002, -1.2944,  1.2740, -0.0884, -0.4328,  0.3349,\n",
      "         0.2376, -0.1202, -0.5006, -0.9151, -0.9417, -1.0427, -0.8981,  0.5469,\n",
      "        -0.8372,  1.1914,  1.9080,  0.2327, -1.0795,  0.1176,  1.8357,  2.4901,\n",
      "        -0.1774])\n",
      "diff: tensor([[2.4795e-05],\n",
      "        [1.3098e-05],\n",
      "        [2.2188e-05],\n",
      "        [1.5799e-05],\n",
      "        [2.3615e-05],\n",
      "        [1.9282e-05],\n",
      "        [2.0411e-05],\n",
      "        [1.8739e-05],\n",
      "        [2.2146e-05],\n",
      "        [1.7245e-05],\n",
      "        [1.8188e-05],\n",
      "        [2.3997e-05],\n",
      "        [1.5371e-05],\n",
      "        [1.5966e-05],\n",
      "        [1.7874e-05],\n",
      "        [1.8743e-05],\n",
      "        [1.5158e-05],\n",
      "        [2.6740e-05],\n",
      "        [2.2938e-05],\n",
      "        [2.1061e-05],\n",
      "        [1.6934e-05],\n",
      "        [1.9588e-05],\n",
      "        [2.2111e-05],\n",
      "        [2.3333e-05],\n",
      "        [2.5556e-05]], grad_fn=<AddBackward0>)\n",
      "t: tensor([22.1389, 13.1774, 27.3478,  3.6728, 18.8948, 10.8205,  8.7794, 13.3292,\n",
      "        12.7528, 10.6322,  8.3776,  5.9212,  5.7636,  5.1647,  6.0217, 14.5855,\n",
      "         6.3829, 18.4057, 22.6523, 12.7238,  4.9465, 12.0414, 22.2239, 26.1024,\n",
      "        10.2933])\n",
      "torch.float64 torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input dtype Double does not match other dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m proj \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#print(proj)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# torch.set_printoptions(profile=\"full\")\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mimplicit_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moutput_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# print(pred)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# print(y)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#print(pred)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#print(y)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36mimplicit_diffusion\u001b[1;34m(diff, temp, mean, std, mean2, std2)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# DERIVED TEMPERATURE OUTPUT FOR NEXT MODULE\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mdtype, mn\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m---> 60\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m proj \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# scaler = StandardScaler()\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# scaler.fit(proj.reshape(-1, 1))\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# scaler.fit(proj)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#proj = scaler.transform(proj.reshape(-1, 1))\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# proj = scaler.transform(proj)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input dtype Double does not match other dtype Float"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for it in tqdm(range(n_epochs)):\n",
    "    loss_epoch = 0\n",
    "    model.train()\n",
    "    for x, y in iter(train_loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        \n",
    "        # get temperature input\n",
    "        temp_input = x[:,13]\n",
    "        print(temp_input.shape)\n",
    "        print(temp_input)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(model(x))\n",
    "        proj = model(x)\n",
    "        #print(proj)\n",
    "        \n",
    "        # torch.set_printoptions(profile=\"full\")\n",
    "        \n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        \n",
    "        #pred.grad.data.copy_(proj.grad.data)\n",
    "        \n",
    "        # proj[0:30,0] = pred\n",
    "        \n",
    "        # print(proj)\n",
    "        \n",
    "        #print(pred)\n",
    "        #print(y)\n",
    "        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        loss = criterion(pred, y)\n",
    "        #print(loss)\n",
    "        #loss= loss.double\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach().item()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if it % 50 == 0:\n",
    "        train_loss.append(loss_epoch/len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        for x, y in iter(test_loader):\n",
    "            x, y = x.to(device).float(), y.to(device).float()\n",
    "            #pred = model(x)\n",
    "            \n",
    "            #mean=0.0\n",
    "            #std=1.0\n",
    "            #mean = torch.tensor(mean).to(device)\n",
    "            #std = torch.tensor(std).to(device)\n",
    "            temp_input = x[:,13] #* std + mean\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            proj = model(x)\n",
    "\n",
    "            pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss_epoch += loss.detach().item()\n",
    "        test_loss.append(test_loss_epoch/len(test_loader))\n",
    "        print(f\"Epoch : {it}, Train_loss: {train_loss[-1]}, Test_loss: {test_loss[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss, label=\"Train\", linewidth=2.5)\n",
    "plt.plot(test_loss, label=\"Test\", linewidth=2.5)\n",
    "plt.grid(\"on\", alpha=0.2)\n",
    "plt.legend(fontsize=18)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return (((true-pred)**2).mean()**0.5).detach().cpu().numpy()\n",
    "\n",
    "def l2_error(true, pred):\n",
    "    return np.linalg.norm(pred.detach().cpu().numpy() - true.detach().cpu().numpy()) / np.linalg.norm(true.detach().cpu().numpy()) \n",
    "\n",
    "def compute_metrics(model, loader, mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    y_ = []\n",
    "    pred_ = []\n",
    "    mean = torch.tensor(mean).to(device)\n",
    "    std = torch.tensor(std).to(device)\n",
    "    for x, y in iter(loader):\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        pred = model(x)\n",
    "        \n",
    "        temp_input = x[:,13]\n",
    "        proj = model(x)\n",
    "        pred = implicit_diffusion(proj, temp_input, input_mean, input_std,\n",
    "                                 output_mean, output_std)        \n",
    "        pred = pred.to(dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        y = y * std + mean\n",
    "        pred = pred * std + mean\n",
    "        \n",
    "        #red = torch.squeeze(pred)\n",
    "        \n",
    "        #rint(pred.shape)\n",
    "        \n",
    "        y_.append(y)\n",
    "        pred_.append(pred)\n",
    "    y_ = torch.cat(y_, dim=0) \n",
    "    pred_ = torch.cat(pred_, dim=0)\n",
    "    \n",
    "    \n",
    "    rmse_temp = rmse(y_[:,0], pred_)\n",
    "    \n",
    "    l2_error_temp = l2_error(y_[:,0], pred_)\n",
    "    return rmse_temp, l2_error_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, test_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Test Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_temp, l2_error_temp = compute_metrics(model, train_loader,  mean = output_mean, std = output_std)\n",
    "print(f\"Train Rmse of Temp: {rmse_temp}\")\n",
    "print(f\"L2 Error  of Temp: {l2_error_temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/heat_diffusion_model_time.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
